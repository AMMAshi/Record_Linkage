---
title: "Record Linkage"
author: "Arwa Ashi"
date: "_`r format(Sys.Date(), '%d %B, %Y')`_"
output:
  pdf_document:
    df_print: kable
    number_sections: yes
    toc: yes
    fig_caption: yes
  html_document: default
include-before: '`\newpage{}`{=latex}'
---

```{r setup, include=FALSE}
# Run knitr chunk options
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      fig.align="center", out.width="70%")
# Load wrangled, tidied and partitioned movielens data based on code provided in project instructions

# Open required package libraries
library(tidyverse)
library(ggplot2)
library(lubridate)
library(stringr)
library(kableExtra)
library(caret)
library(knitr)
library(scales)
library(RecordLinkage)
library(tidyverse)
library(dslabs)
library(diyar)
library(caret)
library(gridExtra)
library(randomForest)
library(reclin2)
# Create plot theme to apply to ggplot2 element text throughout report
plot_theme <- theme(plot.caption = element_text(size = 12, face = "italic"), axis.title = element_text(size = 12))
```
\newpage

# **Introduction**

Digital transformation after COVID 19 has increased the data collecting for public and privet sector. If the data linked in a proper way that would improve the provided service and client experience. This report represent a several data linkage methodologies. There are three stages: Pre-linkage (see data preparation section), Linkage ( see methodology section), and Post-linkage. The report will be divided into data, data exploration, data preparation, methodology, result, and conclusion sections.

# **Data **
Finding an available dataset for data linkage project is not easy. Based on that the 'RLdata500' and 'RLdata10000' datasets under the package 'RecordLinkage' are considered.

# **Data Exploration**

The data contains the first name, last name and date of birth for individuals. Notice that the data field can be different slightly, for example two records refer to the same entity i.e. peter can have a slight change in his last name or his date of birth. The 'RLdata500' and 'RLdata10000' have 7 columns for each, and 500 and 10000 rows consequently. The first name as 'fname_c1' and last name as 'lname_c1' are separated into two columns and date of birth is separated into several columns for year as 'by', month as 'bm', and day as 'bd', See Table 1. 

```{r}
head(RLdata500) %>%
  kable(caption = "Example: First Rows of 'RLdata500' Dataset", align = 'ccclll', booktabs = T,
        format = "latex", linesep = "") %>%
  kable_styling(full_width = FALSE, position = "center")
```

The dataset assumed that it marge individual information from different databases.

# **Data Preparation**
First step is pre-linkage stage which is to prepare the data for evaluation by generate the features that will be used in the models. In order to do that, a 'compare.depdup' function under the 'RecordLinkage' package is used to generate the feature. The generated feature (pair) compare two ids in each row. See Table 2. The number 1 and 0 mean perfect match or no match consequently. If the number is less than 0, then it means that it is a float number for a string comparison. The final column indicates if there is a match or not.

```{r}
pairs_feature_500 <- compare.dedup(RLdata500,
                                   blockfld = list(1,5:7), # match in 5,6,7 columns
                                   strcmp = c(2,3,4),
                                   strcmpfun = levenshteinSim)
matches_500 <- pairs_feature_500$pairs
head(matches_500) %>%
  kable(caption = "Example: Generated Pairs of 'RLdata500' Dataset", align = 'ccclll', booktabs = T,
        format = "latex", linesep = "") %>%
  kable_styling(full_width = FALSE, position = "center")
```

# **Methodology**

The linkage stage that has the objective of matching the records in each 'RLdata500' and 'RLdata10000' datasets with no common unique identifiers and deduplicating with a dataset. There will be two methodologies: a probabilistic method and machine learning method.

The preprocessing stage was done in data preparation section by developing link keys by using blocking as 'blockfld' function under 'compare.dedup' function.

## Probabilistic Method

There are a deterministic method that is a direct match by comparing everything needs to match, and a probabilistic method that is to estimate a probability or liklihood for two records. The focusing here is by using a probabilistic matching. For the classification, a Fellegi-Sunter Model is considered. Define a cut off for string comparing at 80% by using EM algorithm as 'emWeights' function in 'RecordLinkage' package. For a summary of weights for 'RLdata500', see the following:

```{r}
cut_off_500 <- emWeights(pairs_feature_500, cutoff = 0.8)
summary(cut_off_500)
```


See Table 3 for initial matched. The initial matches is used as base to determine threshold. For 'RLdata500', the threshold is 30. See table 4 for final pairs.

```{r}
allPairs_500 <- getPairs(cut_off_500)
head(allPairs_500)%>%
  kable(caption = "Example: Initial Matched. of 'RLdata500' Dataset", align = 'ccclll', booktabs = T,
        format = "latex", linesep = "") %>%
  kable_styling(full_width = FALSE, position = "center")
```



```{r}
finalPairs_500 <- getPairs(cut_off_500, max.weight = 30, min.weight = 0)
head(finalPairs_500,48)%>%
  kable(caption = "Example: Final Matched. of 'RLdata500' Dataset", align = 'ccclll', booktabs = T,
        format = "latex", linesep = "") %>%
  kable_styling(full_width = FALSE, position = "center")
```

## Machine Learning Method

For the machine learning approach (( logistic regression )), a 'reclin2' packages is considered for preparing the data for the algorithm. First, creating pairs by blocking fields by using 'pair_blocking' function in 'reclin2' package. Second, comparing the pairs to get comparing score for each feature by using 'compare_pairs' function in 'reclin2' package. Third, preparing the binary parameters 'TRUE' and 'FALS' by using 'compare_vars'  function in 'reclin2' package. Fourth, using 'glm' function with a family = binomial() for the logistic regression. Fifth, predict the matching probability. Sixth, selecting a matching probability that is greater than 50%. Seventh, generating a FALSE TRUE table for the result evaluation. Finally, generate the Final matching pairs. See table 5.
```{r}
dataset1 <- RLdata500
dataset1['id'] <- identity.RLdata500

dataset2 <- RLdata10000
dataset2['id'] <- identity.RLdata10000

# 1 Creating a paris by using blocking fields
ML_pairs <- pair_blocking(dataset1,dataset1,c("id"))

# 2 Comparing the pairs and get comparing score for each feature
compare_pairs(ML_pairs, on = c("fname_c1","lname_c1","by","bm", "bd"), inplace = TRUE,
              comparators = list(fname_c1 = jaro_winkler(), 
                                 lname_c1 = jaro_winkler(), 
                                 by = jaro_winkler(),
                                 bm = jaro_winkler(),
                                 bd = jaro_winkler()))

# 3 preparing the binary parameters 'TRUE' or 'FALS'
dataset1['known_id'] <- dataset1['id']
setDT(dataset1)

compare_vars(ML_pairs, "y", on_x = "id", on_y = "known_id", 
             y = dataset1, inplace = TRUE)

compare_vars(ML_pairs, "y_true", on_x = "id", 
             on_y = "id", inplace = TRUE)

# 4 ML model - the logistic regression
glm_fit <- glm(y ~ fname_c1 + lname_c1 + by + bm + bd, 
               data = ML_pairs,family = binomial())

# 5 predicting the matching probability
ML_pairs[, `:=`(prob, predict(glm_fit, type = "response", newdata = ML_pairs))]

# 6 selecting a matching probability that is greater than 50%
ML_pairs[, `:=`(select, prob > 0.5)]

# 7 generating a FALSE TRUE table for the result evaluation
table(ML_pairs$select > 0.5, ML_pairs$y_true)

# 8 generate the Final matching pair
ML_FinalPairs <- link(ML_pairs, selection = "select", all_y = TRUE)

head(ML_FinalPairs,160) %>% 
  filter(.y != .x)%>%
  kable(caption = "Example: Final Matched. of 'RLdata500' Dataset", align = 'ccclll', booktabs = T,
        format = "latex", linesep = "") %>%
  kable_styling(full_width = FALSE, position = "center",latex_options = c("scale_down", "hold_position"))

```

# **Result**
Table 4 and 5 have the matching pairs' results by using a probabilistic methodology and logistic regression consequently. 

# **Conclusion**
The probabilistic and machine learning approaches for records linkages are working and matched the records. For the future work, a big dataset would be considered that have more features to have the ability to evaluate the performance of each approach and consider more approaches and assumptions. 
